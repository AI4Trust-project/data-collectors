apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: iceberg-sync-news
  namespace: kafka
  labels:
    strimzi.io/cluster: my-connect-cluster
spec:
  class: io.tabular.iceberg.connect.IcebergSinkConnector
  tasksMax: 1
  config:
    # topics: news
    topics.regex: news.(.*)
    iceberg.control.topic: iceberg-control-news
    # catalog
    iceberg.catalog.catalog-impl: org.apache.iceberg.nessie.NessieCatalog
    iceberg.catalog.uri: http://nessie.default:19120/api/v2
    iceberg.catalog.ref: main
    iceberg.authentication.type: NONE
    # warehouse
    iceberg.catalog.warehouse: s3a://news
    # minio s3
    iceberg.catalog.io-impl: org.apache.iceberg.aws.s3.S3FileIO
    iceberg.catalog.s3.endpoint: http://minio.minio 
    iceberg.catalog.s3.access-key-id: minio
    iceberg.catalog.s3.secret-access-key: minio123
    iceberg.catalog.client.region: us-east-1
    iceberg.catalog.s3.path-style-access: true
    # time to commit and auto create
    iceberg.control.commit.interval-ms: 60000
    iceberg.tables.auto-create-enabled: true
    iceberg.tables.evolve-schema-enabled: true
    iceberg.tables.dynamic-enabled: true
    iceberg.tables.route-field: _table
    # converting messages configuration
    key.converter: org.apache.kafka.connect.storage.StringConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter.schemas.enable: false
    # include dest table derived from topic name
    transforms: "InsertTable,InsertTimestamp"
    transforms.InsertTable.type: "org.apache.kafka.connect.transforms.InsertField$Value"
    transforms.InsertTable.topic.field: "_table"
    transforms.InsertTimestamp.type: "org.apache.kafka.connect.transforms.InsertField$Value"
    transforms.InsertTimestamp.timestamp.field: "_timestamp"